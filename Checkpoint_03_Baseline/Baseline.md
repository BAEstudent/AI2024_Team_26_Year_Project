# Baseline
## Выбор архитектуры
Для данной задачи мы решили пойти относительно современным путём: воспользоваться претрейном для генерации фичей из наших аугментированных фотографий. Мы посмотрели лекции по Computer Vision с нашей программы, где говорилось, что самыми современными моделями для дообучения сейчас являются две архитектуры: EfficientNet и RegNet. 

Для дообучения данных архитектур мы хотели взять веса, полученные исследователями на датасете ImageNet21k, однако у RegNet есть огромное количество адаптивных архитектур и весов под нашу задачу мы не нашли. Таким образом, мы остановились на дообучении только EfficientNet'ов разных версий. Веса для этих версий были взяты из библиотеки timm. 

Поскольку наши аугментированные фотографии на данном этапе представляли собой квадратные фотографии разрешения 450x450, то мы выбрали несколько архитектур EfficientNet'a, разрешения входных данных которых были близки к нашим значениям. Так выбор пал на 4 модели:

- EfficientNet B5 (input 456x456);
- EfficientNetV2 S (input 384x384);
- EfficientNetV2 M (input 480x480);
- EfficientNetV2 L (input 480x480);
После того, как мы достали новые фичи из каждой из вышеперечисленных моделей, следовало обучение новой головы, в качестве которой была взята мультиклассовая логистическая регрессия (Softmax голова).
## Дополнительная аугментация
Так как разрешение входных данных для этих моделей немного отличалось от нашего, была проведена дополнительная аугментациия и сформированы наборы данных с нужными размерностями изображений. Таким образом, мы хотели улучшить результаты моделей, подавая им данные в соответствующих разрешениях. Исходные фотографии имели размерность 450x600 пикселей. Для EfficientNetV2 S изображения были обрезаны до 384x384, а для остальных моделей производился паддинг двумя белыми прямоугольниками (например, фото обрезалось до 450x480 и дополнялось с двух сторон белыми прямоугольниками до размерности 480x480). Потом с полученными фотографиями сделать все аугментации, которые мы делали ранее: повороты на 90, 180, 270 градусов, добавление гауссовского блюра, а также отражение фото относительно своей оси. По итогу мы имели 4 папки входных данных: 
- исходные аугментации размера 450x450;
- аугментации 384x384;
- аугментации 456x456 с белым паддингом;
- аугментации 480x480 с белым паддингом;
## Обучение
Так мы обучили 4 вышеперечисленные модели, а также решили обучить EfficientNetV2 S на исходных аугментациях, которые мы получили после EDA. Так мы решили сравнить, улучшится ли качество после обрезания фото до размера входных данных нейронной сети или нет. В конце мы каждый раз обучали softmax на новых фичах. 
## Метрики
В качестве метрик мы взяли две ключевые метрики: Accuracy и Average One vs Rest Roc Auc. То есть мы считали долю угаданных среди всех классов и средний Roc Auc, где для каждого класса Roc Auc считался подходом один против всех. Метрика Accuracy считалась целевой в соревновании, откуда взят данный датасет, поэтому мы выбирали лучшую модель по наибольшей Accuracy.
## Результаты
- EfficientNetV2 S (input 450x450): Accuracy - 88.08%; ROC-AUC - 0.9834;
- EfficientNet B5 (input 456x456): Accuracy - 88.99%, ROC-AUC - 0.9852;
- EfficientNetV2 M (input 480x480): Accuracy - 90.55%, ROC-AUC - 0.9850;
- EfficientNetV2 L (input 480x480): Accuracy - 92.54%, ROC-AUC - 0.9826;
- EfficientNetV2 S (input 384x384): Accuracy - 86.70%, ROC-AUC - 0.9820.

Как мы можем заметить, обрезание исходного разрешения уменьшило нашу Accuracy в архитектуре EfficientNetV2 S. Также можем заметить, что ROC-AUC сильно не изменялся в данных моделях, вероятно потому что вероятности, которые он приписывал разным фотографиям также являются случайной величиной и имея такую маленькую погрешность, они могли случайно привести к волатильности в ROC-AUC score. По Accuracy же на валидационной выборке побеждает с большим отрывом EfficientNetV2 L с паддингом белыми прямоугольниками. 

Мы решили обучить её ещё раз на большем количестве эпох (Best_Baseline.ipynb) и получили ещё более хорошее качество:

-  EfficientNetV2 L (input 480x480, 300 epochs): Accuracy - 93.26%, ROC-AUC - 0.9856.

Здесь же мы получили ещё большую Accuracy и ROC-AUC стал самым большим среди всех моделей, но с маленьким отрывом. 
P.S. Для сравнения: Лучшая модель в соревновании 2018 года имела Accuracy - 89.5%